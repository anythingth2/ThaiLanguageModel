{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1016,
     "status": "ok",
     "timestamp": 1574583127746,
     "user": {
      "displayName": "CHATCHAI SHAETAN",
      "photoUrl": "",
      "userId": "12596253677762100444"
     },
     "user_tz": -420
    },
    "id": "VLAGIZUiZHbb",
    "outputId": "ff969d43-9418-4e34-dc3a-a822c6106503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9948,
     "status": "ok",
     "timestamp": 1574582259682,
     "user": {
      "displayName": "CHATCHAI SHAETAN",
      "photoUrl": "",
      "userId": "12596253677762100444"
     },
     "user_tz": -420
    },
    "id": "1-9gBe-WaXh6",
    "outputId": "6b87fe39-20db-4743-9db9-caf2b9aa0755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "README.md\n",
      "\r",
      "             19 100%    0.00kB/s    0:00:00  \r",
      "             19 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=5/6)\n",
      "character_copus.txt\n",
      "\r",
      "            259 100%    0.72kB/s    0:00:00  \r",
      "            259 100%    0.72kB/s    0:00:00 (xfr#2, to-chk=4/6)\n",
      "data_gen.py\n",
      "\r",
      "          2,559 100%    3.13kB/s    0:00:00  \r",
      "          2,559 100%    3.13kB/s    0:00:00 (xfr#3, to-chk=3/6)\n",
      "model.ipynb\n",
      "\r",
      "         32,768  43%   25.42kB/s    0:00:01  \r",
      "         65,536  87%   50.83kB/s    0:00:00  \r",
      "         74,896 100%   58.09kB/s    0:00:01 (xfr#4, to-chk=2/6)\n",
      "model.py\n",
      "\r",
      "              0 100%    0.00kB/s    0:00:00 (xfr#5, to-chk=1/6)\n",
      "wiki_prepare.py\n",
      "\r",
      "          2,019 100%    4.59kB/s    0:00:00  \r",
      "          2,019 100%    4.59kB/s    0:00:00 (xfr#6, to-chk=0/6)\n"
     ]
    }
   ],
   "source": [
    "# !cp -r -v drive/My\\ Drive/ThaiLanguageModel/* .\n",
    "!rsync -a --progress --exclude=\"dataset\" drive/My\\ Drive/ThaiLanguageModel/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kuieie6Jar-h"
   },
   "outputs": [],
   "source": [
    "!rm -rf dataset\n",
    "!mkdir dataset\n",
    "!mkdir dataset/thwiki-words\n",
    "!cp drive/My\\ Drive/ThaiLanguageModel/dataset/thwiki-words.zip dataset/thwiki-words.zip\n",
    "!unzip dataset/thwiki-words.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32986,
     "status": "ok",
     "timestamp": 1574582591882,
     "user": {
      "displayName": "CHATCHAI SHAETAN",
      "photoUrl": "",
      "userId": "12596253677762100444"
     },
     "user_tz": -420
    },
    "id": "DNWxQHqLceNY",
    "outputId": "f9c0e539-8f2d-4c77-8f2e-4e6e1553312a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ujson\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: ujson\n",
      "  Building wheel for ujson (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ujson: filename=ujson-1.35-cp37-cp37m-linux_x86_64.whl size=69600 sha256=effde6ec631d01ff6dc88b2e273b4d1064dae9e3b031532d02f2fc16ff7f6144\n",
      "  Stored in directory: /home/porlolicon/.cache/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "Successfully built ujson\n",
      "Installing collected packages: ujson\n",
      "Successfully installed ujson-1.35\n",
      "Collecting pythainlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/94/1ca5c23bfdbc0f27fa26e5eeda47d8ff422cbbd3f38c0b8a160fa17a2583/pythainlp-2.0.7-py3-none-any.whl (11.0MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0MB 12.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nltk>=3.2.2 (from pythainlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 10.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marisa-trie (from pythainlp)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz\n",
      "Collecting tqdm (from pythainlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/62/6f823501b3bf2bac242bd3c320b592ad1516b3081d82c77c1d813f076856/tqdm-4.39.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 12.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tinydb (from pythainlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/83/2d46115b89640e9b85b94df47216547396e94125245dd3ade186036ce976/tinydb-3.15.1-py2.py3-none-any.whl\n",
      "Collecting dill (from pythainlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests (from pythainlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 11.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /home/porlolicon/miniconda3/envs/chai37/lib/python3.7/site-packages (from pythainlp) (2019.2)\n",
      "Requirement already satisfied: six in /home/porlolicon/miniconda3/envs/chai37/lib/python3.7/site-packages (from nltk>=3.2.2->pythainlp) (1.12.0)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->pythainlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests->pythainlp)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/porlolicon/miniconda3/envs/chai37/lib/python3.7/site-packages (from requests->pythainlp) (2019.6.16)\n",
      "Collecting idna<2.9,>=2.5 (from requests->pythainlp)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: nltk, marisa-trie, dill\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449908 sha256=fb12210495448c99ac352e3702dc891e46ccb24e187f57fb8b223e29dbac5b60\n",
      "  Stored in directory: /home/porlolicon/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Building wheel for marisa-trie (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp37-cp37m-linux_x86_64.whl size=877165 sha256=896f4810bbeb4b2f2e3980ecd87fe8cc712ed51f45407f8cc34b385e4e5b2527\n",
      "  Stored in directory: /home/porlolicon/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=8cace22c627a36f10b1f154c86ca95447f42609cd06c604b3150d57d198fd1b1\n",
      "  Stored in directory: /home/porlolicon/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "Successfully built nltk marisa-trie dill\n",
      "Installing collected packages: nltk, marisa-trie, tqdm, tinydb, dill, urllib3, chardet, idna, requests, pythainlp\n",
      "Successfully installed chardet-3.0.4 dill-0.3.1.1 idna-2.8 marisa-trie-0.7.5 nltk-3.4.5 pythainlp-2.0.7 requests-2.22.0 tinydb-3.15.1 tqdm-4.39.0 urllib3-1.25.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ujson\n",
    "!pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6910,
     "status": "ok",
     "timestamp": 1574591426785,
     "user": {
      "displayName": "CHATCHAI SHAETAN",
      "photoUrl": "",
      "userId": "12596253677762100444"
     },
     "user_tz": -420
    },
    "id": "9gMynek4Zatn",
    "outputId": "2b96ed64-2bef-4fc7-8cd4-f573df8fe4d1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import CuDNNLSTM, Bidirectional, RepeatVector, Dense, TimeDistributed, Activation, Input\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from pathlib import Path\n",
    "import data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCdvB5KUcODh"
   },
   "outputs": [],
   "source": [
    "NUM_VOCAB = data_gen.NUM_VOCAB\n",
    "length = 32\n",
    "batch_size = 32\n",
    "train_gen = data_gen.sentence_generator(Path('dataset/thwiki-words'),\n",
    "                                        length,\n",
    "                                        batch_size,\n",
    "                                        adversarial=data_gen.random_blank(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1126 00:16:01.211741 139818380121920 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W1126 00:16:03.606885 139818380121920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1126 00:16:06.450649 139818380121920 module_wrapper.py:137] From /home/porlolicon/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weight/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5986,
     "status": "ok",
     "timestamp": 1574591435739,
     "user": {
      "displayName": "CHATCHAI SHAETAN",
      "photoUrl": "",
      "userId": "12596253677762100444"
     },
     "user_tz": -420
    },
    "id": "FW_yNCtydMBL",
    "outputId": "c700ea67-4901-4c61-b669-a7e9faad7dbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1124 22:20:31.104708 140365793371968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 32, 128)           77824     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32, 128)           99328     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 32, 64)            41472     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 32, 64)            25088     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 32, 64)            25088     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 32, 64)            25088     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 32, 128)           66560     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 32, 128)           99328     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 32, 86)            11094     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 86)            0         \n",
      "=================================================================\n",
      "Total params: 470,870\n",
      "Trainable params: 470,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "activation = 'relu'\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True), input_shape=(length, NUM_VOCAB)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "\n",
    "\n",
    "# model.add(RepeatVector(length))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(32, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True)))\n",
    "model.add(Activation(activation))\n",
    "model.add(TimeDistributed(Dense(NUM_VOCAB)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "ZkJzxvib_9NQ",
    "outputId": "3d599216-9be5-45df-fd23-9e169206f57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      " 433/4096 [==>...........................] - ETA: 1:40 - loss: 0.0547 - acc: 0.9860"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-03a390b0f77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     epochs=100)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=4096,\n",
    "                    initial_epoch=41,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weight/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads_func = data_gen.random_blank(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: อยากอกหักแต$อุปสรรคอยู$ที่ห$้าตา\n",
      "output: อยากอกหักแต่อุปสรรคอยู่ที่หน้าตา\n"
     ]
    }
   ],
   "source": [
    "text = 'อยากอกหักแต่อุปสรรคอยู่ที่หน้าตา'\n",
    "text = ads_func(text)\n",
    "print('input:', text)\n",
    "encoded = data_gen.encode_text(text, 32)\n",
    "pred = model.predict(np.expand_dims(encoded, axis=0))[0]\n",
    "pred_text = data_gen.decode_text(pred)\n",
    "print('output:', pred_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "model.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
